{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9eaa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "### switch to parent folder in order to import functions\n",
    "import os\n",
    "os.chdir('..')\n",
    "from pathlib import Path\n",
    "assert Path('./dataset').exists(), f'We are in the wrong directory. Restart may be required.'\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "from lib.utils import dBm_gray, plot_dict, calc_loss_with_mask, print_metricsTest, gray_dBm, calculate_fspl_with_offset, rbf_interpolate, tps_interpolate, get_rm_adjusted\n",
    "from lib.data_loading import load_env_inputs, load_tx_inputs\n",
    "from lib.modulesIPPNet import RadioNetAnySize\n",
    "import torch\n",
    "from PIL import Image\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acd0f5c",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc84129",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_target = (32, 32)\n",
    "measurement_dir = Path('dataset/data_seminar_room')\n",
    "data_file_old = measurement_dir / '2501/measured_data_2501.json' # only LoS\n",
    "data_file_new = measurement_dir / '2511/measured_data_2511.json' # with whiteboard blocking LoS\n",
    "\n",
    "with open(data_file_old, 'r') as f:\n",
    "    data_old = json.load(f)\n",
    "with open(data_file_new, 'r') as f:\n",
    "    data_new  = json.load(f)\n",
    "\n",
    "data_new_mit = {t : {m : md for m, md in td.items() if 'mit' in m and not 'Widerholung' in m} for t, td in data_new.items()}    \n",
    "data_new_ohne = {t : {m : md for m, md in td.items() if 'ohne' in m and not 'Widerholung' in m} for t, td in data_new.items()}    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6ce53",
   "metadata": {},
   "source": [
    "# Generate tensors from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd5c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_file = measurement_dir / '2501/raster_seminar_room_256/projectwi_files_tx.json'\n",
    "with open(tx_file, 'r') as f:\n",
    "    tx_coords_dict = json.load(f)\n",
    "\n",
    "pl_trnc = -71\n",
    "pl_max = -12\n",
    "\n",
    "def extract_data(observation_areas: list, test_areas: list, percentage_threshold: float, tx_id: int, seed: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Extract and prepare observation and ground truth data from measurement areas.\n",
    "    \n",
    "    Args:\n",
    "        observation_areas: List of tuples (data_dict, area_names) for observation data\n",
    "        test_areas: List of tuples (data_dict, area_names) for ground truth data\n",
    "        percentage_threshold: Minimum percentage of available samples to include a point\n",
    "        tx_id: Transmitter ID (1-4)\n",
    "        seed: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (obs_inp, gt, gt_mask, obs_mask, tx_coords) as tensors\n",
    "    \"\"\"\n",
    "    n_obs_points = sum(len(d[1]) for d in observation_areas)\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    point_ids = rng.integers(low=0, high=20, size=n_obs_points)\n",
    "    point_idx = 0\n",
    "\n",
    "    obs_inp = np.ones((32, 32)) * (-500)\n",
    "    for data_dict, obs_area_list in observation_areas:\n",
    "        for obs_area in obs_area_list:\n",
    "            tx_data = data_dict[f\"Tx{tx_id}\"][obs_area].values()\n",
    "            points_usable = [point_data for point_data in tx_data if point_data[\"percentage_samples_available\"] > percentage_threshold]\n",
    "            try:\n",
    "                point_used = points_usable[point_ids[point_idx]%len(points_usable)]\n",
    "            except:\n",
    "                print(f'{point_ids = }\\n{point_idx = }\\n{points_usable = }\\n{len(points_usable)=}\\n{point_idx%len(points_usable)=}')\n",
    "                raise Exception('stop')\n",
    "            assert obs_inp[*point_used['coordinates']] == -500, f'{point_used=} already appears in obs_inp?'\n",
    "            obs_inp[*point_used['coordinates']] = point_used['pl']\n",
    "            point_idx += 1\n",
    "\n",
    "    obs_inp = torch.tensor(dBm_gray(obs_inp, pl_trnc=pl_trnc, pl_max=pl_max, clip=True))\n",
    "    obs_mask = obs_inp > 0\n",
    "\n",
    "    gt = np.ones((32, 32)) * (-500)\n",
    "    for data_dict, obs_area_list in test_areas:\n",
    "        for obs_area in obs_area_list:\n",
    "            tx_data = data_dict[f\"Tx{tx_id}\"][obs_area].values()\n",
    "            for point_data in tx_data:\n",
    "                if point_data[\"percentage_samples_available\"] > percentage_threshold:\n",
    "                    assert gt[*point_data['coordinates']] == -500, f'{gt[*point_data[\"coordinates\"]]=}'\n",
    "                    if obs_mask[*point_data['coordinates']] > 0:\n",
    "                        continue\n",
    "                    gt[*point_data['coordinates']] = point_data[\"pl\"]\n",
    "    gt = torch.tensor(dBm_gray(gt, pl_trnc=pl_trnc, pl_max=pl_max, clip=True))\n",
    "    gt_mask = gt > 0\n",
    "\n",
    "    return obs_inp.unsqueeze(0).unsqueeze(0), gt.unsqueeze(0).unsqueeze(0), gt_mask.unsqueeze(0).unsqueeze(0), obs_mask.unsqueeze(0).unsqueeze(0), torch.tensor(tx_coords_dict[str(tx_id - 1)]).unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "def get_model_inputs(config : dict, tx_id : int, obs_inp : torch.Tensor, dataset_dir : Path) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Relevant code from the dataset to generate CNN inputs.\n",
    "    \"\"\"\n",
    "    with open(Path(config['dataset_dir']) / config['env_raster_subdir']  / 'rasterization_parameters.json', 'r') as f:\n",
    "        raster_params = json.load(f)\n",
    "    n_classes = len(raster_params['materials']) + 1\n",
    "    raster_heights = raster_params['heights']\n",
    "    x_steps = raster_params['x_steps']\n",
    "    y_steps = raster_params['y_steps']\n",
    "    x_step_size = raster_params['x_max'] / raster_params['x_steps']\n",
    "    y_step_size = raster_params['y_max'] / raster_params['y_steps']\n",
    "    env_id = 'wi_files'\n",
    "\n",
    "\n",
    "    inputs_cnn = torch.empty((0, x_steps, y_steps))\n",
    "    if config.get('use_material_properties', False) or config.get('use_material_classes', True):\n",
    "        inputs_cnn = load_env_inputs(\n",
    "            inputs=inputs_cnn, \n",
    "            env_id_here=env_id, \n",
    "            env_raster_subdir=dataset_dir / (f'raster_seminar_room_256' if not 'bin' in config['env_raster_subdir'] else 'raster_seminar_room_256_bin'), \n",
    "            raster_heights=raster_heights, \n",
    "            n_classes=n_classes, \n",
    "            use_material_classes=config.get('use_material_classes', True), \n",
    "            use_material_properties=config.get('use_material_properties', False)\n",
    "        )\n",
    "\n",
    "    inputs_cnn = torch.concat([inputs_cnn, torch.repeat_interleave(torch.repeat_interleave(obs_inp.squeeze(0), 8, -1), 8, -2)])\n",
    "\n",
    "\n",
    "    inputs_cnn, _ = load_tx_inputs(\n",
    "        env_tx_subdir=dataset_dir / f'raster_seminar_room_256',\n",
    "        env_id_here=env_id,\n",
    "        tx_id=tx_id - 1,\n",
    "        use_tx_one_hot=config['use_tx_one_hot'],\n",
    "        inputs=inputs_cnn,\n",
    "        x_step_size=x_step_size,\n",
    "        y_step_size=y_step_size,\n",
    "        use_tx_distance=config['use_tx_distance'],\n",
    "        use_Tx_distToRx=config['use_Tx_distToRx'],\n",
    "        rx_height=1,\n",
    "        use_log_distance=config['use_log_distance'],\n",
    "        use_fspl=config['use_fspl'],\n",
    "        frequency_hz=5.82e9,\n",
    "        return_coords=True,\n",
    "        pl_max=pl_max,\n",
    "        pl_trnc=pl_trnc,\n",
    "    ) # type: ignore\n",
    "\n",
    "    return inputs_cnn.to(torch.float32).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e6b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_id = 3\n",
    "\n",
    "obs_inp, gt, gt_mask, obs_mask, tx_coords = extract_data(\n",
    "    observation_areas=[(data_old, [f'MeasurementArea_{k}' for k in [1,2,3,4,7,8]]),\n",
    "                        (data_new_mit, [f'MeasurementArea_{k}-mit_Abschattung' for k in [5, 6]])\n",
    "                        ],\n",
    "    test_areas=[(data_new_mit, [f'MeasurementArea_{k}-mit_Abschattung' for k in [5, 6]])],\n",
    "    percentage_threshold=50,\n",
    "    tx_id=tx_id,\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "plot_dict(dict(obs_inp=obs_inp, gt=gt, gt_mask=gt_mask, obs_mask=obs_mask), in_batch_id=0, close_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b2de27",
   "metadata": {},
   "source": [
    "# Test baselines on example sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd57ceaa",
   "metadata": {},
   "source": [
    "## FSPL, interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    'fspl_offset' : (calculate_fspl_with_offset, [None]), \n",
    "    'rbf' : (rbf_interpolate, [None, 1, 2, 3, 5, 7, 9]), \n",
    "    'tps' : (tps_interpolate, [0, 0.01, 0.1, 0.25, 0.5, 0.75, 1])\n",
    "}\n",
    "for name, (fun, param_list) in methods.items():\n",
    "    for param in param_list:\n",
    "        output = fun(inputs=obs_inp, observation_mask=obs_mask, tx_coords=tx_coords, pl_trnc=pl_trnc, pl_max=pl_max, param=param)\n",
    "        diff = (gt - output) * gt_mask\n",
    "        err = calc_loss_with_mask(pred=output, target=gt, mask=gt_mask, observation_mask=obs_mask, alpha=1, metrics=None)\n",
    "        plot_dict(dict(obs_inp=obs_inp, gt=gt, output=output, diff=diff), in_batch_id=0, close_fig=False, suptitle=f'{name} {param} {torch.sqrt(err) * (71-12):.1f}dB RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535a0db1",
   "metadata": {},
   "source": [
    "## Ray-Tracing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea565fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoS\n",
    "sim_output_dir = measurement_dir / '2501'\n",
    "rms_rt_np = {tx : np.zeros((32, 32)) for tx in range(1, 5)}\n",
    "rms_rt = {}\n",
    "for tx in rms_rt_np.keys():\n",
    "    img = np.array(Image.open(sim_output_dir / f'sim_{tx=}.png')) / 255\n",
    "    rms_rt_np[tx][:img.shape[0], :img.shape[1]] = img\n",
    "    rms_rt[tx] = torch.Tensor(rms_rt_np[tx]).unsqueeze(0)\n",
    "\n",
    "# nLoS as well\n",
    "sim_output_dir_whiteboard = measurement_dir / '2511'\n",
    "rms_rt_np_whiteboard = {tx : np.zeros((32, 32)) for tx in range(1, 5)}\n",
    "rms_rt_whiteboard = {}\n",
    "for tx in rms_rt_np.keys():\n",
    "    img = np.array(Image.open(sim_output_dir_whiteboard / f'sim_{tx=}.png')) / 255\n",
    "    rms_rt_np_whiteboard[tx][:img.shape[0], :img.shape[1]] = img\n",
    "    rms_rt_whiteboard[tx] = torch.Tensor(rms_rt_np_whiteboard[tx]).unsqueeze(0)\n",
    "\n",
    "\n",
    "output = get_rm_adjusted(inputs=obs_inp, observation_mask=obs_mask, rm=rms_rt[tx_id])\n",
    "diff = (gt - output) * gt_mask\n",
    "err = calc_loss_with_mask(pred=output, target=gt, mask=gt_mask, observation_mask=obs_mask, alpha=1, metrics=None)\n",
    "plot_dict(dict(obs_inp=obs_inp, gt=gt, output=output, diff=diff), in_batch_id=0, close_fig=False, suptitle=f'RT {torch.sqrt(err) * (71-12):.1f}dB RMSE')\n",
    "\n",
    "output_whiteboard = get_rm_adjusted(inputs=obs_inp, observation_mask=obs_mask, rm=rms_rt_whiteboard[tx_id])\n",
    "diff = (gt - output_whiteboard) * gt_mask\n",
    "err = calc_loss_with_mask(pred=output_whiteboard, target=gt, mask=gt_mask, observation_mask=obs_mask, alpha=1, metrics=None)\n",
    "plot_dict(dict(obs_inp=obs_inp, gt=gt, output=output_whiteboard, diff=diff), in_batch_id=0, close_fig=False, suptitle=f'RT whiteboard {torch.sqrt(err) * (71-12):.1f}dB RMSE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d116299",
   "metadata": {},
   "source": [
    "## CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path('logs/RadioNetAnySize/20251210-12:17:45') # bin, pert\n",
    "# model_dir = Path('logs/RadioNetAnySize/20251110-12:25:12') # 'No Environment'\n",
    "weights = torch.load(model_dir / 'BestModel.pt', weights_only=True)\n",
    "for k, v in weights.items():\n",
    "    if not 'conv' in k:\n",
    "        continue\n",
    "    else:\n",
    "        in_ch = v.shape[1]\n",
    "        break\n",
    "\n",
    "with open(model_dir / 'parameters.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "model = RadioNetAnySize(inputs=in_ch, initial_downsampling=int(config['raster_size'] / 32))\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4099ab31",
   "metadata": {},
   "source": [
    "Without showing the whiteboard in the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a7b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_cnn = get_model_inputs(config, tx_id, obs_inp, dataset_dir=Path('dataset/data_seminar_room/2501'))\n",
    "output_cnn = model(inputs_cnn)\n",
    "diff = (gt - output_cnn) * gt_mask\n",
    "err = calc_loss_with_mask(pred=output_cnn, target=gt, mask=gt_mask, observation_mask=obs_mask, alpha=1, metrics=None)\n",
    "plot_dict(dict(obs_inp=obs_inp, gt=gt, output=output_cnn, diff=diff), in_batch_id=0, close_fig=False, suptitle=f'CNN {torch.sqrt(err) * (71-12):.1f}dB RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f00e945",
   "metadata": {},
   "source": [
    "## With whiteboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f9a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_cnn = get_model_inputs(config, tx_id, obs_inp, dataset_dir=Path('dataset/data_seminar_room/2511'))\n",
    "output_cnn = model(inputs_cnn)\n",
    "diff = (gt - output_cnn) * gt_mask\n",
    "err = calc_loss_with_mask(pred=output_cnn, target=gt, mask=gt_mask, observation_mask=obs_mask, alpha=1, metrics=None)\n",
    "plot_dict(dict(obs_inp=obs_inp, gt=gt, output=output_cnn, diff=diff), in_batch_id=0, close_fig=False, suptitle=f'CNN {torch.sqrt(err) * (71-12):.1f}dB RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a681d2",
   "metadata": {},
   "source": [
    "# Now in a Loop to generate some statistics of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bddf435",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d189fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_id = 3\n",
    "\n",
    "n_test = 500\n",
    "for name, (fun, param_list) in methods.items():\n",
    "    for param in param_list:\n",
    "        print(f'\\n{name=}\\t{param=}')\n",
    "        metrics = defaultdict(float)\n",
    "        for sample_id in range(n_test):\n",
    "            obs_inp, gt, gt_mask, obs_mask, tx_coords = extract_data(\n",
    "                observation_areas=[(data_old, [f'MeasurementArea_{k}' for k in [1,2,3,4,7,8]]),\n",
    "                                    (data_new_mit, [f'MeasurementArea_{k}-mit_Abschattung' for k in [5, 6]])\n",
    "                                    ],\n",
    "                test_areas=[(data_new_mit, [f'MeasurementArea_{k}-mit_Abschattung' for k in [5, 6]])],\n",
    "                percentage_threshold=50,\n",
    "                tx_id=tx_id,\n",
    "                seed=sample_id\n",
    "            )\n",
    "            output = fun(inputs=obs_inp, observation_mask=obs_mask, tx_coords=tx_coords, pl_trnc=pl_trnc, pl_max=pl_max, param=param)\n",
    "            diff = (gt - output) * gt_mask\n",
    "            err = calc_loss_with_mask(pred=output, target=gt, mask=gt_mask, observation_mask=obs_mask, alpha=1, metrics=metrics)\n",
    "        print_metricsTest(metrics=metrics, epoch_samples=n_test, phase='test', pl_max=pl_max, pl_trnc=pl_trnc, log_name=None)\n",
    "        plot_dict(dict(obs_inp=obs_inp, gt=gt, output=output, diff=diff), in_batch_id=0, close_fig=False, suptitle=f'{name} {param} {torch.sqrt(err) * (71-12):.1f}dB RMSE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9976fd",
   "metadata": {},
   "source": [
    "Ray-Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9180155",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors_plot = []\n",
    "\n",
    "metrics_rt = defaultdict(float)\n",
    "metrics_rt_wb = defaultdict(float)\n",
    "for sample_id in range(n_test):\n",
    "    obs_inp, gt, gt_mask, obs_mask, tx_coords = extract_data(\n",
    "        observation_areas=[(data_old, [f'MeasurementArea_{k}' for k in [1,2,3,4,7,8]]),\n",
    "                            (data_new_mit, [f'MeasurementArea_{k}-mit_Abschattung' for k in [5, 6]])\n",
    "                            ],\n",
    "        test_areas=[(data_new_mit, [f'MeasurementArea_{k}-mit_Abschattung' for k in [5, 6]])],\n",
    "        percentage_threshold=50,\n",
    "        tx_id=tx_id,\n",
    "        seed=sample_id\n",
    "    )\n",
    "\n",
    "    output = get_rm_adjusted(inputs=obs_inp, observation_mask=obs_mask, rm=rms_rt[tx_id])\n",
    "    diff = (gt - output) * gt_mask\n",
    "    err = calc_loss_with_mask(pred=output, target=gt, mask=gt_mask, observation_mask=obs_mask, alpha=1, metrics=metrics_rt)\n",
    "\n",
    "    output_whiteboard = get_rm_adjusted(inputs=obs_inp, observation_mask=obs_mask, rm=rms_rt_whiteboard[tx_id])\n",
    "    diffwb = (gt - output_whiteboard) * gt_mask\n",
    "    errwb = calc_loss_with_mask(pred=output_whiteboard, target=gt, mask=gt_mask, observation_mask=obs_mask, alpha=1, metrics=metrics_rt_wb)\n",
    "\n",
    "print_metricsTest(metrics=metrics_rt, epoch_samples=n_test, phase='test', pl_max=pl_max, pl_trnc=pl_trnc, log_name=None)\n",
    "print_metricsTest(metrics=metrics_rt_wb, epoch_samples=n_test, phase='test', pl_max=pl_max, pl_trnc=pl_trnc, log_name=None)\n",
    "\n",
    "plot_dict(dict(obs_inp=obs_inp, gt=gt, output=output, diff=diff), in_batch_id=0, close_fig=False, suptitle=f'RT {torch.sqrt(err) * (71-12):.1f}dB RMSE')\n",
    "plot_dict(dict(obs_inp=obs_inp, gt=gt, output=output_whiteboard, diff=diffwb), in_batch_id=0, close_fig=False, suptitle=f'RT WB {torch.sqrt(errwb) * (71-12):.1f}dB RMSE')\n",
    "\n",
    "tensors_plot.extend([obs_inp[0], gt[0], output[0], output_whiteboard[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab581a5c",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603e08e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    for (model_dir, name) in [\n",
    "            (Path('logs/RadioNetAnySize/20251210-12:17:45'), 'Binary, SNDA'),\n",
    "            (Path('logs/RadioNetAnySize/20251110-12:25:12'), 'No Environment'),\n",
    "        ]:\n",
    "\n",
    "        try:\n",
    "            weights = torch.load(model_dir / 'BestModel.pt', weights_only=True)\n",
    "        except FileNotFoundError as e:\n",
    "            print(str(model_dir), e)\n",
    "            continue\n",
    "\n",
    "        for k, v in weights.items():\n",
    "            if not 'conv' in k:\n",
    "                continue\n",
    "            else:\n",
    "                in_ch = v.shape[1]\n",
    "                break\n",
    "\n",
    "        with open(model_dir / 'parameters.json', 'r') as f:\n",
    "            config = json.load(f)\n",
    "\n",
    "        model = RadioNetAnySize(inputs=in_ch, initial_downsampling=int(config['raster_size'] / 32))\n",
    "        model.load_state_dict(weights)\n",
    "        for experiment, dataset_dir in [('object visible', measurement_dir / '2501'), ('object not visible', measurement_dir / '2511')]:\n",
    "            print(f'\\n\\n{name}\\t{experiment}')\n",
    "            metrics = defaultdict(float)\n",
    "            for sample_id in range(n_test):\n",
    "                obs_inp, gt, gt_mask, obs_mask, tx_coords = extract_data(\n",
    "                    observation_areas=[(data_old, [f'MeasurementArea_{k}' for k in [1,2,3,4,7,8]]),\n",
    "                                        (data_new_mit, [f'MeasurementArea_{k}-mit_Abschattung' for k in [5, 6]])\n",
    "                                        ],\n",
    "                    test_areas=[(data_new_mit, [f'MeasurementArea_{k}-mit_Abschattung' for k in [5, 6]])],\n",
    "                    percentage_threshold=50,\n",
    "                    tx_id=tx_id,\n",
    "                    seed=sample_id\n",
    "                )\n",
    "                inputs_cnn = get_model_inputs(config, tx_id, obs_inp, dataset_dir=dataset_dir)\n",
    "                output_cnn = model(inputs_cnn)\n",
    "                diff = (gt - output_cnn) * gt_mask\n",
    "                err = calc_loss_with_mask(pred=output_cnn, target=gt, mask=gt_mask, observation_mask=obs_mask, alpha=1, metrics=metrics)\n",
    "            print_metricsTest(metrics=metrics, epoch_samples=n_test, phase='test', pl_max=pl_max, pl_trnc=pl_trnc, log_name=None)\n",
    "            plot_dict(dict(obs_inp=obs_inp, gt=gt, output=output_cnn, diff=diff), in_batch_id=0, close_fig=False, suptitle=f'CNN {name} {dataset_dir.stem}{torch.sqrt(err) * (71-12):.1f}dB RMSE')\n",
    "            tensors_plot.append(output_cnn[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indoor_public",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
